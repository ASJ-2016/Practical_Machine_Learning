titb <- paste0(">",bestz)
}
for (p in pz) {
for (m in mx) {
for (extr1 in c(ex)) {
for (extr2 in c(ex)) {
for (extr3 in c(ex)) {
extr <- c(extr1, extr2, extr3)
print(paste0("1",extr))
expost <- VARXExpostAnalysis(xt,zt,pz=p,mx=m,h=h,extrapolate=extr, explag=explag, ...)
iter <- rbind(iter, c(expost$mape, aic=expost$aic, bic=expost$bic, nobe=expost$nobe, p, m, extr))
mape <- mean(expost$mape[bestz])
naive <- mean(expost$naive[bestz])
if (mape < best_cost) {
best_cost <- mape
best <- list(p=p,m=m,extr=extr)
best_analysis <- expost
if (plot) {
tit = paste0(tit," MAPE=", round(best_cost,3),
" (NAIVE=", round(naive,3),")",
" AIC=", round(expost$aic,2),
" pz=", p, " mx=", m,
" lag=", explag,
" fitb=",titb)#, " extr=", extr1, extr2, extr3))
PlotExpostAnalysis(expost,zt,xt,nplot=nplot,tit=tit)
}
}
}
}
}
}
}
colnames(iter)[1:8] <- c("MAPE1","MAPE2","MAPE3","AIC","BIC","NOBE","PZ","MX")
return(list(best=best, iter=iter, expost=expost))
}
#12 3 fit3
# DSE !!!
# Exploracion del espacio (p,m) y eleccion segun el mejor MAPE
# 3 6 (0.067 vs 0.117)
test=33
# h = 12
# mono_02_12  <- VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=1:6,mx=1:12,h=h, plot=TRUE, test=test, explag=2, tit="Mono", bestz=1:2)
# mono_02x    <- VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=7:12,mx=1:6,h=h, plot=TRUE, test=test, explag=2, tit="Mono", bestz=1:2)
#
# h = 3
# mbasket_02  <- VARXFullAnalysis(xtMONO_ASIA, ztBASKET_EURO, pz=1:6,mx=1:12,h=h, plot=TRUE, test=test, explag=2, tit="Mix", bestz=1:2)
# mbasket_02x <- VARXFullAnalysis(xtMONO_ASIA, ztBASKET_EURO, pz=7:12,mx=1:6,h=h, plot=TRUE, test=test, explag=2, tit="Mix", bestz=1:2)
#
# h = 12
# mono_01_12  <- VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=1:6,mx=1:12,h=h, plot=TRUE, test=test, explag=1, tit="Mono", bestz=1:2)
# mono_01x    <- VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=7:12,mx=1:6,h=h, plot=TRUE, test=test, explag=1, tit="Mono", bestz=1:2)
#
# h = 3
# mbasket_01_12  <- VARXFullAnalysis(xtMONO_ASIA, ztBASKET_EURO, pz=1:6,mx=1:12,h=h, plot=TRUE, test=test, explag=1, tit="Mix", bestz=1:2)
# mbasket_01x <- VARXFullAnalysis(xtMONO_ASIA, ztBASKET_EURO, pz=7:12,mx=1:6,h=h, plot=TRUE, test=test, explag=1, tit="Mix", bestz=1:2)
#
#
# save(mono_01_12,    mono_01x,    mono_02_12, mono_02x,
#      mbasket_01_12, mbasket_01x, mbasket_02, mbasket_02x,
#      file = GDFile("/ELIX_basket_results1.Rdata"))
load(file = GDFile("/ELIX_basket_results1.Rdata"))
# Pre-analisis
all_01 <- rbind(mono_01_12$iter, mono_01x$iter)
all_01 %>% as.data.frame() %>% mutate(mape12=0.5*(MAPE1+MAPE2), mape123=0.3*(MAPE1+MAPE2+MAPE3)) -> all_01
min_mape123 <- min(all_01$mape123)
min_mape12 <- min(all_01$mape12)
min_mape3  <- min(all_01$MAPE3)
min_AIC <- min(all_01$AIC)
min_BIC <- min(all_01$BIC)
all_01[ which(all_01$mape123 == min_mape123),]
all_01[ which(all_01$mape12 == min_mape12),]
#           MAPE1      MAPE2      MAPE3      AIC      BIC NOBE PZ MX V9 V10 V11     mape12    mape123
# 105 0.007065334 0.01671886 0.02411434 21.39529 25.72085   61 12  3  1   1   1 0.01189209 0.01436956
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=12,mx=3,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2)
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=12,mx=3,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO[,1:2], pz=12,mx=3,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2)
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO[,3, drop=FALSE], pz=12,mx=3,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=3)
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=3,mx=5,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
all_01
all_01
mono_01_12
xtMONO_ASIA
ztMONO_EURO
mbasket_01x
ztBASKET_EURO
ztBASKET_EURO
calmonth
ztMONO
ztMONO
ztMONO
dim(ztMONO)
str(ztMONO)
?VARXFullAnalysis
?VARX
expost$mape
all_01
all_01
a <- VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=12,mx=3,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2)
str(a)
a$best
a$iter
a$expost
a$iter
a$expost$mape
a
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=3,mx=5,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=1,mx=1,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
MyFunc <- function(pp,xx){
for (x in pp){
for (y in xx){
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=x,mx=y,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
}
}
}
MyFunc(pp=1,xx=1)
rm(list=ls(all=TRUE))
rm(list=ls(all=TRUE))
require(MTS)
require(dplyr)
require(forecast)
require(ggplot2)
GDFile <- function(file, project="I+D R ELIX/3.prototipo/") {
paste0(GDRIVE,project,file)
}
source(GDFile("/elix_var_basket_functions2.R"))
# Datos para el anÃ¡lisis
# save(calmonth, ztMONO, xtMONO_ASIA, ztMONO_EURO, ztBASKET, xtBASKET_ASIA, ztBASKET_EURO,
load(file=GDFile("/ELIX_basket_analysis.Rdata"))
VARXFullAnalysis <- function(xt,zt,pz=1:3,mx=1:6,h=12, plot=FALSE, bestz=NULL, ex=TRUE, explag=1,
tit="", nplot=2,...) {
best_cost <- 9999999
iter <- NULL
best_analysis <- NULL
if (is.null(bestz)) {
bestz <- 1:ncol(zt)
titb <- NULL
} else {
titb <- paste0(">",bestz)
}
for (p in pz) {
for (m in mx) {
for (extr1 in c(ex)) {
for (extr2 in c(ex)) {
for (extr3 in c(ex)) {
extr <- c(extr1, extr2, extr3)
print(paste0("1",extr))
expost <- VARXExpostAnalysis(xt,zt,pz=p,mx=m,h=h,extrapolate=extr, explag=explag, ...)
iter <- rbind(iter, c(expost$mape, aic=expost$aic, bic=expost$bic, nobe=expost$nobe, p, m, extr))
mape <- mean(expost$mape[bestz])
naive <- mean(expost$naive[bestz])
if (mape < best_cost) {
best_cost <- mape
best <- list(p=p,m=m,extr=extr)
best_analysis <- expost
if (plot) {
tit = paste0(tit," MAPE=", round(best_cost,3),
" (NAIVE=", round(naive,3),")",
" AIC=", round(expost$aic,2),
" pz=", p, " mx=", m,
" lag=", explag,
" fitb=",titb)#, " extr=", extr1, extr2, extr3))
PlotExpostAnalysis(expost,zt,xt,nplot=nplot,tit=tit)
}
}
}
}
}
}
}
colnames(iter)[1:8] <- c("MAPE1","MAPE2","MAPE3","AIC","BIC","NOBE","PZ","MX")
return(list(best=best, iter=iter, expost=expost))
}
load(file = GDFile("/ELIX_basket_results1.Rdata"))
# Pre-analisis
all_01 <- rbind(mono_01_12$iter, mono_01x$iter)
all_01 %>% as.data.frame() %>% mutate(mape12=0.5*(MAPE1+MAPE2), mape123=0.3*(MAPE1+MAPE2+MAPE3)) -> all_01
min_mape123 <- min(all_01$mape123)
min_mape12 <- min(all_01$mape12)
min_mape3  <- min(all_01$MAPE3)
min_AIC <- min(all_01$AIC)
min_BIC <- min(all_01$BIC)
all_01[ which(all_01$mape123 == min_mape123),]
all_01[ which(all_01$mape12 == min_mape12),]
MyFunc <- function(pp,xx){
for (x in pp){
for (y in xx){
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=x,mx=y,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
}
}
}
MyFunc(pp=1,xx=1)
MyFunc <- function(pp,xx){
for (x in seq(1,pp,by=2)){
for (y in seq(1,xx,by=2)){
print(x,y)
# VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=x,mx=y,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
}
}
}
MyFunc(pp=10,xx=10)
MyFunc <- function(pp,xx){
for (x in seq(1,pp,by=2)){
for (y in seq(1,xx,by=2)){
cat(x,y)
# VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=x,mx=y,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
}
}
}
MyFunc(pp=10,xx=10)
MyFunc <- function(pp,xx){
for (x in seq(1,pp,by=2)){
for (y in seq(1,xx,by=2)){
print(x)
print(y)
# VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=x,mx=y,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
}
}
}
MyFunc(pp=10,xx=10)
MyFunc <- function(pp,xx){
for (x in seq(1,pp,by=2)){
for (y in seq(1,xx,by=2)){
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=x,mx=y,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
}
}
}
MyFunc(pp=15,xx=15)
MyFunc(pp=(6:15),xx=15)
mono_01_12
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=5,mx=1,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=7,mx=1,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
MyFunc <- function(pp,xx){
for (x in seq(7,pp,by=2)){
for (y in seq(1,xx,by=2)){
VARXFullAnalysis(xtMONO_ASIA, ztMONO_EURO, pz=x,mx=y,h=12, plot=TRUE, test=33, explag=1, tit="Mono", bestz=1:2, ex=FALSE)
}
}
}
MyFunc(pp=15,xx=9)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
segmentationOriginal
str(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit
modFit$finalModel
suppressMessages(library(rattle))
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
install.packages("rattle")
library(rattle)
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
plot(cartModel$finalModel, uniform=T)
plot(modFit$finalModel, uniform=T)
text(modFit$finalModel, cex=0.8)
modFit$finalModel
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[, -1]
newdata = as.data.frame(t(colMeans(olive)))
newdata
olive
olive
newdata
modolive <- train(Area ~ ., method = "rpart", data = olive)
library(caret)
modolive <- train(Area ~ ., method = "rpart", data = olive)
modolive
predict(modolive, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values, prediction){
sum(((prediction > 0.5) * 1) != values) / length(values)
}
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.test
str(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
modvowel
order(varImp(modvowel), decreasing = T)
rm(list=ls(all=TRUE))
require(MTS)
require(dplyr)
require(forecast)
require(ggplot2)
bestOrder
VARXorder
VARX
refVARX
VARXpred
df = read.table("RunningTimes.txt", header = TRUE)
str(df)
df
MyFunc <- function(mydata){
mydata$x <- mydata$ID
return(out=mydata)
}
df = read.table("RunningTimes.txt", header = TRUE)
getwd()
df = read.table("RunningTimes.txt", header = TRUE)
str(df)
df
MyFunc <- function(mydata){
mydata$x <- mydata$ID
return(out=mydata)
}
MyFunc(df)
MyFunc(df)
MyFunc <- function(mydata){
mydata$x <- mydata$ID
# return(out=mydata)
}
MyFunc(df)
MyFunc <- function(mydata){
mydata$x <- mydata$ID
return(out=mydata)
}
a <- MyFunc(df)
str(a)
cat("by Alejandro Serrano", "\n")
cat("Date: ", format(Sys.Date(),  "%a %d %b 20%y"), "\n")
cat(R.version.string)
URL_train <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
URL_test <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(URL_train), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(URL_test), na.strings=c("NA","#DIV/0!",""))
str(training, list.len=18)
dim(testing)
train <- training[ , colSums(is.na(training)) == 0]
test <- testing[ , colSums(is.na(testing)) == 0]
train <- train[, -nearZeroVar(train)]
test <- test[, -nearZeroVar(test)]
train <- train[, -c(1, 3:6)]
test <- test[, -c(1, 3:6)]
str(train, list.len=18)
dim(test)
set.seed(123456)
toTrain <- createDataPartition(y=training$classe, p=0.60, list=FALSE)
inTrain  <- train[toTrain,]
inTest  <- train[-toTrain,]
dim(inTrain)
dim(inTest)
corrMatrix <- cor(na.omit(inTrain[sapply(inTrain, is.numeric)]))
corrplot(corrMatrix, type = "upper", tl.cex = 0.6, tl.col = 1)
prop.table(table(inTrain$user_name, inTrain$classe), 1)
# set.seed(123456)
# t0 <- Sys.time()
#
# # Random Forest - VERY SLOW
# mod_rf <- train(classe ~ ., data = inTrain, method = "rf")
# save(mod_rf, file="mod_rf.RData")
# t1 <- Sys.time()
#
# # Stochastic Gradient Boosting - VERY SLOW
# mod_gbm <- train(classe ~ ., data = inTrain, method = "gbm", verbose = FALSE)
# save(mod_gbm, file="mod_gbm.RData")
# t2 <- Sys.time()
#
# # Linear discriminant analysis - FAST
# mod_lda <- train(classe ~ ., data = inTrain, method = "lda")
# save(mod_lda, file="mod_lda.RData")
# t3 <- Sys.time()
#
# cat("Time to train the random forest: ", t1-t0 , "\n")
# cat("Time to train the random forest: ", t2-t1 , "\n")
# cat("Time to train the random forest: ", t3-t2 , "\n")
load(file="mod_rf.RData")
load(file="mod_gbm.RData")
load(file="mod_lda.RData")
source(paste0(COURSERADIR, "./08 - Practical Machine Learning/Quizes and Assigments/Practical_Machine_Learning"))
source(paste0(COURSERADIR, "./08 - Practical Machine Learning/Quizes and Assigments/Practical_Machine_Learning"))
source(paste0(COURSERADIR, "08 - Practical Machine Learning/Quizes and Assigments/Practical_Machine_Learning"))
setwd(paste0(COURSERADIR, "./08 - Practical Machine Learning/Quizes and Assigments/Practical_Machine_Learning"))
getwd()
load(file="mod_rf.RData")
load(file="mod_gbm.RData")
load(file="mod_lda.RData")
mod_rf
mod_gbm
mod_lda
inTest
library(caret)
library(gbm)
library(randomForest)
library(corrplot)
URL_train
training
r
r
str(training, list.len=18)
dim(testing)
str(train, list.len=18)
dim(test)
train <- training[ , colSums(is.na(training)) == 0]
test <- testing[ , colSums(is.na(testing)) == 0]
train <- train[, -nearZeroVar(train)]
test <- test[, -nearZeroVar(test)]
train <- train[, -c(1, 3:6)]
test <- test[, -c(1, 3:6)]
str(train, list.len=18)
dim(test)
set.seed(123456)
toTrain <- createDataPartition(y=training$classe, p=0.60, list=FALSE)
inTrain  <- train[toTrain,]
inTest  <- train[-toTrain,]
dim(inTrain)
dim(inTest)
corrMatrix <- cor(na.omit(inTrain[sapply(inTrain, is.numeric)]))
corrplot(corrMatrix, type = "upper", tl.cex = 0.6, tl.col = 1)
mod_lda
inTest
pred_rf <- predict(mod_rf, inTest)
pred_gbm <- predict(mod_gbm, inTest)
pred_lda <- predict(mod_lda, inTest)
confusionMatrix(pred_rf, inTest$diagnosis)$overall[1]
pred_rf
inTest$diagnosis
inTest$classe
confusionMatrix(pred_rf, inTest$classe)
confusionMatrix(pred_rf, inTest$classe)$overall
confusionMatrix(pred_rf, inTest$classe)$overall[1]
# Accuracy using random forests
confusionMatrix(pred_rf, inTest$classe)$overall[1]
# Accuracy using boosting
confusionMatrix(pred_gbm, inTest$classe)$overall[1]
# Accuracy using linear discriminant analysis
confusionMatrix(pred_lda, inTest$classe)$overall[1]
varImp(pred_rf)
pred_rf
varImp(mod_rf)
mod_rf$finalModel
pred_rf_test <- predict(mod_rf, test)
pred_rf_test
confusionMatrix(pred_rf_test, test$classe)$overall
test
test$classe
pred_rf_test
for (i in 1:lenght(pred_rf_test)){
print(i, " ", pred_rf_test[i])
}
for (i in pred_rf_test){
print(i, " ", pred_rf_test[i])
}
for (i in 1:length(pred_rf_test)){
print(i, " ", pred_rf_test[i])
}
for (i in 1:length(pred_rf_test)){
cat(i, " ", pred_rf_test[i])
}
for (i in 1:length(pred_rf_test)){
cat(i, " ", pred_rf_test[i], "/n")
}
for (i in 1:length(pred_rf_test)){
cat(i, " ", pred_rf_test[i], "\n")
}
pred_rf_test
data.frame(CM_rf, CM_gmb, CM_lda)
# Accuracy using random forests
CM_rf <- confusionMatrix(pred_rf, inTest$classe)$overall[1]
# Accuracy using boosting
CM_gmb <- confusionMatrix(pred_gbm, inTest$classe)$overall[1]
# Accuracy using linear discriminant analysis
CM_lda <- confusionMatrix(pred_lda, inTest$classe)$overall[1]
data.frame(CM_rf, CM_gmb, CM_lda)
format(data.frame(CM_rf, CM_gmb, CM_lda), digits=2)
# Accuracy using random forests
Rand-Forest <- confusionMatrix(pred_rf, inTest$classe)$overall[1]
# Accuracy using boosting
Boosting <- confusionMatrix(pred_gbm, inTest$classe)$overall[1]
# Accuracy using linear discriminant analysis
Linear-Discrim <- confusionMatrix(pred_lda, inTest$classe)$overall[1]
format(data.frame(CM_rf, CM_gmb, CM_lda), digits=2)
format(data.frame(Rand-Forest, Boosting, Linear-Discrim), digits=2)
# Accuracy using random forests
CM_rf <- confusionMatrix(pred_rf, inTest$classe)$overall[1]
# Accuracy using boosting
CM_gmb <- confusionMatrix(pred_gbm, inTest$classe)$overall[1]
# Accuracy using linear discriminant analysis
CM_lda <- confusionMatrix(pred_lda, inTest$classe)$overall[1]
format(data.frame(CM_rf, CM_gmb, CM_lda), digits=2)
